{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOy1dyqjYuV7uiIp75liqUQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Apresenta√ß√£o:\n","\n","    A ideia aqui √© construir um modelo de LLM implementando o RAG,\n","    Retrieval Augmented Generation. Visando essa efervec√™ncia de\n","    concursos p√∫blicos, a ideia aqui √© criar um modelo especializado\n","    em direito, vamos come√ßar com direito constitucional.\n","\n","Nota:\n","\n","    As ideias tratadas aqui que j√° tenham sido tratadas antes, n√£o\n","    ser√£o reescritas aqui, ent√£o, caso haja interesse, busque os c√≥digos\n","    anteriores no repositorio do github."],"metadata":{"id":"po2TFAstM7rM"}},{"cell_type":"code","source":["# Instala√ß√µes Necess√°rias:\n","!pip install openai\n","!pip install cohere\n","!pip install tiktoken\n","!pip install vectordb2\n","!pip install tqdm\n","!pip install langchain\n","!pip install transformers[torch]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dSp1j6w1NIKa","executionInfo":{"status":"ok","timestamp":1707843057504,"user_tz":180,"elapsed":74214,"user":{"displayName":"Andr√© Amorim","userId":"04859568826717067647"}},"outputId":"abdc371b-23e5-44ed-e264-f827b945d5e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.12.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.14)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (4.47)\n","Requirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.9.3)\n","Requirement already satisfied: backoff<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.2.1)\n","Requirement already satisfied: fastavro<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.9.3)\n","Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (6.11.0)\n","Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n","Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.26.18)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2024.2.2)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n","Requirement already satisfied: vectordb2 in /usr/local/lib/python3.10/dist-packages (0.1.9)\n","Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from vectordb2) (2.1.0+cu121)\n","Requirement already satisfied: transformers>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from vectordb2) (4.35.2)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from vectordb2) (1.23.5)\n","Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from vectordb2) (1.2.2)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from vectordb2) (1.11.4)\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (from vectordb2) (2.3.1)\n","Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (from vectordb2) (1.7.4)\n","Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (from vectordb2) (2.15.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->vectordb2) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->vectordb2) (3.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->vectordb2) (2.1.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (0.20.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (0.15.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.10.0->vectordb2) (4.66.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->vectordb2) (3.8.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->vectordb2) (0.1.99)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->vectordb2) (9.4.0)\n","Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->vectordb2) (0.16.1)\n","Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->vectordb2) (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (3.3.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (4.23.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (2.4.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (0.36.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (1.57.0)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (2.15.1)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (2.15.0)\n","Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.13.0->tensorflow-text->vectordb2) (2.15.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->vectordb2) (2.1.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers->vectordb2) (8.1.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10.0->vectordb2) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10.0->vectordb2) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10.0->vectordb2) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.10.0->vectordb2) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->vectordb2) (1.3.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (0.42.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (3.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (1.3.1)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->vectordb2) (3.2.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n","Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.6)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.25)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n","Requirement already satisfied: langchain-community<0.1,>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.19)\n","Requirement already satisfied: langchain-core<0.2,>=0.1.22 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.22)\n","Requirement already satisfied: langsmith<0.1,>=0.0.83 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.87)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.14)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n","Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.22->langchain) (3.7.1)\n","Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.22->langchain) (23.2)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.2.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n","Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n","Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.27.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n"]}]},{"cell_type":"markdown","source":["# Implementando o RAG:\n","\n","    RAG √© Retrieval Augmented Generation √© um m√©todo de melhoria de um\n","    LLM baseado no que eu vou chamar aqui de \"revalida√ß√£o\". Antes do\n","    modelo dar a resposta, a ideia √© ele validar essa resposta num conjunto\n","    de documentos especializados.\n","\n","    √â como se, antes do modelo dar a resposta, ele fosse checar a resposta\n","    com um especialista."],"metadata":{"id":"5qOeuTe4NGl8"}},{"cell_type":"markdown","source":["**Preparando o texto base**"],"metadata":{"id":"GgmmYaWeQZtX"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"En0F0izGM6L2","executionInfo":{"status":"ok","timestamp":1707842871370,"user_tz":180,"elapsed":49868,"user":{"displayName":"Andr√© Amorim","userId":"04859568826717067647"}},"outputId":"8554b393-83aa-42b5-8b49-6195a4bd07f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+http://github.com/vioshyvo/mrpt/\n","  Cloning http://github.com/vioshyvo/mrpt/ to /tmp/pip-req-build-v8ks6qlb\n","  Running command git clone --filter=blob:none --quiet http://github.com/vioshyvo/mrpt/ /tmp/pip-req-build-v8ks6qlb\n","  warning: redirecting to https://github.com/vioshyvo/mrpt/\n","  Resolved http://github.com/vioshyvo/mrpt/ to commit 88cc6f40782ca0f8de7491279766ded01d767861\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from mrpt==1.0) (1.23.5)\n","Building wheels for collected packages: mrpt\n","  Building wheel for mrpt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mrpt: filename=mrpt-1.0-cp310-cp310-linux_x86_64.whl size=1561746 sha256=bbc28dc9bc2c0595047c4b35e4ca53c84995ff017c8689fee8de634aea4f9df6\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-tp38aw78/wheels/61/f0/46/8fd08e2aa4be121079dc3ef4634352680489c4028bdb57e4de\n","Successfully built mrpt\n","Installing collected packages: mrpt\n","Successfully installed mrpt-1.0\n"]}],"source":["# MRPT - fast nearest neighbor search with random projection\n","!pip install git+http://github.com/vioshyvo/mrpt/"]},{"cell_type":"code","source":["# Bibliotecas para requisi√ß√£o e tratamento do texto base:\n","import re\n","import requests"],"metadata":{"id":"BOeHRxc6NFb_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Importando o Texto bruto:\n","bruto_text = requests.get('https://raw.githubusercontent.com/abjur/constituicao/main/CONSTITUICAO.md').text\n","\n","# Otimiza√ß√£o do Texto:\n","padrao_capitulo = r'^##\\s+(.*)$' # A ideia √© pegar tudo que vem depois do ##\n","sections = re.split(padrao_capitulo, bruto_text, flags=re.MULTILINE)\n","sections = [section.strip() for section in sections[1:]]"],"metadata":{"id":"r662fDdoP_tG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Indexando os dados no VectorDB**"],"metadata":{"id":"-3I4PVgdQzQJ"}},{"cell_type":"code","source":["from tqdm import tqdm\n","from vectordb import Memory\n","from langchain.text_splitter import MarkdownHeaderTextSplitter"],"metadata":{"id":"rclUy_RYQPUu","colab":{"base_uri":"https://localhost:8080/","height":349},"executionInfo":{"status":"error","timestamp":1707843230016,"user_tz":180,"elapsed":459,"user":{"displayName":"Andr√© Amorim","userId":"04859568826717067647"}},"outputId":"49b2030d-e112-40a2-cfbf-887c82c18233"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"cannot import name 'Memory' from 'vectordb' (/usr/local/lib/python3.10/dist-packages/vectordb/__init__.py)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-ca4ba1ba5480>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvectordb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_splitter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMarkdownHeaderTextSplitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'Memory' from 'vectordb' (/usr/local/lib/python3.10/dist-packages/vectordb/__init__.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["# Instanciando o SGBD:\n","memory = Memory(chunking_strategy={'mode':'sliding_window',\n","                                   'window_size':128, # Chunk_size\n","                                   'overlap':8 # Chunk Overlap / Janela Deslizante\n","                                   })"],"metadata":{"id":"TCT7X6itQtdA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenizando as strings:\n","padrao_capitulo = [(\"##\",\"Capitulo\")]\n","markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=padrao_capitulo)\n","sections = markdown_splitter.split_text(bruto_text)"],"metadata":{"id":"tq7dIuGPRXDS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Indexando os dados:\n","for i in tqdm(range(0,len(sections))):\n","  capitulo = sections[i].metadata\n","  texto = sections[i].page_content\n","\n","  metadata = {'capitulo':capitulo,\n","              'origem':'Constitui√ß√£o Federal'}\n","\n","  memory.save(texto,metadata)"],"metadata":{"id":"8I6kUtshRKif"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Teste de Pesquisa:\n","memory.search('direitos dos trabalhadores', top_n=5)"],"metadata":{"id":"1crD-M7fRRL3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Constru√ß√£o do LLM:"],"metadata":{"id":"Q9-5dLTSUY06"}},{"cell_type":"code","source":["#import nltk\n","#import pathlib"],"metadata":{"id":"v6Voc3vbWwP5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#nltk.download('machado', download_dir='../data/gpt/raw')\n","#\n","#!mv ../data/gpt/raw/corpora/machado.zip ../data/gpt/raw/machado.zip\n","#!unzip ../data/gpt/raw/machado.zip -d ../data/gpt/raw\n","#!rm -R ../data/gpt/raw/corpora\n","#!rm ../data/gpt/raw/machado.zip"],"metadata":{"id":"dHuBU9MpW2mS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Abrindo o arquivo para extrair o conteudo:\n","#with open('../data/gpt/raw/machado/contos/macn001.txt', 'r', encoding='iso-8859-1') as f:\n","#    lines = f.read().splitlines()\n","#\n","## Juntando todas os livros\n","#text = []\n","#for text_path in sorted(pathlib.Path(\"../data/gpt/raw/machado/\").rglob(\"*.txt\")):\n","#    with open(text_path, 'r', encoding='iso-8859-1') as f:\n","#        lines = f.read().splitlines()\n","#    text += lines\n","#\n","#text = \" \".join(text)\n","#\n","#with open(\"../data/raw/machado-all.txt\", \"w\") as output:\n","#     output.write(text)"],"metadata":{"id":"OwOJn9I6Wuan"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#precisamos de um corpus bem robusto, por√©m n√£o t√£o gigante\n","!wget -O ./sample_data/crepusculoDosIdolos.txt https://raw.githubusercontent.com/mfmarlonferrari/NietzscheLLM/main/crepusculoDosIdolos.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lB6JCPsZUk08","executionInfo":{"status":"ok","timestamp":1707087124774,"user_tz":180,"elapsed":662,"user":{"displayName":"Andr√© Amorim","userId":"04859568826717067647"}},"outputId":"734ee1cd-1c7b-4544-943a-a1d67dd5930d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-02-04 22:51:58--  https://raw.githubusercontent.com/mfmarlonferrari/NietzscheLLM/main/crepusculoDosIdolos.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 162098 (158K) [text/plain]\n","Saving to: ‚Äò./sample_data/crepusculoDosIdolos.txt‚Äô\n","\n","./sample_data/crepu 100%[===================>] 158.30K  --.-KB/s    in 0.03s   \n","\n","2024-02-04 22:51:58 (5.45 MB/s) - ‚Äò./sample_data/crepusculoDosIdolos.txt‚Äô saved [162098/162098]\n","\n"]}]},{"cell_type":"code","source":["PATH = './sample_data/'\n","dados_treino = 'crepusculoDosIdolos.txt'"],"metadata":{"id":"wggUIcJwUlQW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Criando o tonkenizer baseado no algoritmo BPE\n","from tokenizers.implementations import ByteLevelBPETokenizer\n","from tokenizers.processors import BertProcessing\n","from transformers import (RobertaTokenizer,RobertaForMaskedLM,\n","                          RobertaConfig,LineByLineTextDataset,\n","                          DataCollatorForLanguageModeling,\n","                          Trainer, TrainingArguments,pipeline)"],"metadata":{"id":"P3WAJydZUu63"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instanciando o modelo:\n","tokenizer = ByteLevelBPETokenizer()\n","\n","tokenizer.train(files=[PATH+dados_treino],vocab_size=52_000,\n","                min_frequency=2, special_tokens=[\n","                    \"<s>\",\n","                    \"<pad>\",\n","                    \"</s>\",\n","                    \"<unk>\",\n","                    \"<mask>\"])"],"metadata":{"id":"Iv12cej7Voos"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Salvando modelo:\n","!rm -r ./sample_data/RAW_MODEL\n","!mkdir ./sample_data/RAW_MODEL\n","tokenizer.save_model(PATH+\"RAW_MODEL\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0urx5jfcU9bu","executionInfo":{"status":"ok","timestamp":1707087325388,"user_tz":180,"elapsed":399,"user":{"displayName":"Andr√© Amorim","userId":"04859568826717067647"}},"outputId":"0a17e423-2b51-42e1-f67b-b5bb7a03d157"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["rm: cannot remove './sample_data/RAW_MODEL': No such file or directory\n"]},{"output_type":"execute_result","data":{"text/plain":["['./sample_data/RAW_MODEL/vocab.json', './sample_data/RAW_MODEL/merges.txt']"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# Instanciando modelo:\n","tokenizer = ByteLevelBPETokenizer(\n","    PATH+'RAW_MODEL'+'/vocab.json',\n","    PATH+'RAW_MODEL'+'/merges.txt')\n","\n","tokenizer._tokenizer.post_processor = BertProcessing(\n","    (\"</s\",tokenizer.token_to_id(\"</s>\")),\n","    (\"<s>\", tokenizer.token_to_id(\"<s>\"))\n",")\n","tokenizer.enable_truncation(max_length=512)"],"metadata":{"id":"b1CGjXP_U3zG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instanciando o Tokenizer do LLM escolhido:\n","tokenizer = RobertaTokenizer.from_pretrained(PATH+'RAW_MODEL',max_len=512)"],"metadata":{"id":"ni8-wYrvVWQ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" # Configurando o Transformer\n"," config = RobertaConfig(\n","     vocab_size=52_000,\n","     max_position_embeddings = 512,\n","     num_attention_heads = 12,\n","     num_hidden_layers = 6,\n","     type_vocab_size = 1)"],"metadata":{"id":"68hkEX6NWYid"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instanciando Modelo:\n","model = RobertaForMaskedLM(config=config)"],"metadata":{"id":"2dqbXZL2WcEl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenizando os dados de Treino:\n","dataset = LineByLineTextDataset(\n","    tokenizer=tokenizer,\n","    file_path=PATH+dados_treino,\n","    block_size=128\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gnv-V6EcWd4m","executionInfo":{"status":"ok","timestamp":1707087648071,"user_tz":180,"elapsed":1907,"user":{"displayName":"Andr√© Amorim","userId":"04859568826717067647"}},"outputId":"2ea58ad5-8595-4676-86c3-f963c3896e5f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:119: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Teste:\n","tokenizer.decode(dataset.examples[7]['input_ids'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"V44OZofjWks_","executionInfo":{"status":"ok","timestamp":1707087667382,"user_tz":180,"elapsed":345,"user":{"displayName":"Andr√© Amorim","userId":"04859568826717067647"}},"outputId":"55919052-bd14-4f7a-c774-48fbc07a0c8a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<s>na escola b√©lica da vida ‚Äî o que n√£o me faz morrer me torna mais forte.</s>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, mlm=True, mlm_probability=0.1)"],"metadata":{"id":"flbI-0ZgWp19"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Elementos do treinamento:\n","training_args = TrainingArguments(\n","    output_dir=PATH+'RAW_MODEL',\n","    overwrite_output_dir=True,\n","    num_train_epochs=1200,\n","    per_device_train_batch_size=64,\n","    save_steps=10_000,\n","    save_total_limit=2,\n","    prediction_loss_only=True)\n","\n","# Treinanmento:\n","Trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=dataset)"],"metadata":{"id":"OyAZxoPsWyTm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fit:\n","Trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":392},"id":"eD-nboqzW3Kd","executionInfo":{"status":"ok","timestamp":1707092992016,"user_tz":180,"elapsed":5263789,"user":{"displayName":"Andr√© Amorim","userId":"04859568826717067647"}},"outputId":"f1b8b36a-6c8f-4e12-c75b-24d6d998efd3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4800' max='4800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4800/4800 1:27:41, Epoch 1200/1200]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>6.550400</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>5.226500</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>4.217900</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>3.230900</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>2.382700</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.717100</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>1.235900</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.919400</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.749400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=4800, training_loss=2.7748859246571858, metrics={'train_runtime': 5263.4105, 'train_samples_per_second': 51.526, 'train_steps_per_second': 0.912, 'total_flos': 8992119855513600.0, 'train_loss': 2.7748859246571858, 'epoch': 1200.0})"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["Trainer.save_model(PATH+'RAW_MODEL')"],"metadata":{"id":"i_9jJHZBc2J2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Testando o LLM:\n","fill_mask = pipeline(\n","    \"fill-mask\",\n","    model=PATH+'RAW_MODEL',\n","    tokenizer=PATH+'RAW_MODEL')\n","\n","# Primeiro teste:\n","texto = 'Digo que o amor √© <mask>'\n","fill_mask(texto)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"otv_M0d8stUJ","executionInfo":{"status":"ok","timestamp":1707093491364,"user_tz":180,"elapsed":3823,"user":{"displayName":"Andr√© Amorim","userId":"04859568826717067647"}},"outputId":"387c6e4e-27c1-4685-bbbb-e916a5290d8d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'score': 0.05255282297730446,\n","  'token': 300,\n","  'token_str': ' um',\n","  'sequence': 'Digo que o amor √© um'},\n"," {'score': 0.040366280823946,\n","  'token': 271,\n","  'token_str': ' de',\n","  'sequence': 'Digo que o amor √© de'},\n"," {'score': 0.028334809467196465,\n","  'token': 961,\n","  'token_str': ' humanidade',\n","  'sequence': 'Digo que o amor √© humanidade'},\n"," {'score': 0.0263307336717844,\n","  'token': 414,\n","  'token_str': ' ‚Äî',\n","  'sequence': 'Digo que o amor √© ‚Äî'},\n"," {'score': 0.01727619580924511,\n","  'token': 575,\n","  'token_str': ' h√°',\n","  'sequence': 'Digo que o amor √© h√°'}]"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["# Segundo teste:\n","texto = 'O <mask> da moral: basear na l√≥gica dos fracos'\n","fill_mask(texto)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RZQ3YDL9s21F","executionInfo":{"status":"ok","timestamp":1707093517062,"user_tz":180,"elapsed":239,"user":{"displayName":"Andr√© Amorim","userId":"04859568826717067647"}},"outputId":"06ddaeda-48f9-48d6-a71b-c6d1494ba808"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'score': 0.11579568684101105,\n","  'token': 800,\n","  'token_str': ' erro',\n","  'sequence': 'O erro da moral: basear na l√≥gica dos fracos'},\n"," {'score': 0.033164724707603455,\n","  'token': 480,\n","  'token_str': ' \"',\n","  'sequence': 'O \" da moral: basear na l√≥gica dos fracos'},\n"," {'score': 0.027672506868839264,\n","  'token': 459,\n","  'token_str': ' moral',\n","  'sequence': 'O moral da moral: basear na l√≥gica dos fracos'},\n"," {'score': 0.015147262252867222,\n","  'token': 338,\n","  'token_str': ' por',\n","  'sequence': 'O por da moral: basear na l√≥gica dos fracos'},\n"," {'score': 0.013160984963178635,\n","  'token': 389,\n","  'token_str': 'res',\n","  'sequence': 'Ores da moral: basear na l√≥gica dos fracos'}]"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["from transformers import RobertaForCausalLM\n","\n","# Carregando o modelo treinado\n","modelo = RobertaForCausalLM.from_pretrained(PATH+'RAW_MODEL')\n","tokenizer = RobertaTokenizer.from_pretrained(PATH+'RAW_MODEL')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9feijMppuWh9","executionInfo":{"status":"ok","timestamp":1707094104049,"user_tz":180,"elapsed":3291,"user":{"displayName":"Andr√© Amorim","userId":"04859568826717067647"}},"outputId":"da6024ca-f874-4541-817c-516fb148c710"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n"]}]},{"cell_type":"code","source":["# Fun√ß√£o para gerar respostas\n","def gerar_resposta(texto_entrada, max_length=100, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95):\n","    # Tokenizando a entrada\n","    tokens = tokenizer.encode(texto_entrada, return_tensors=\"pt\")\n","\n","    # Obtendo a sa√≠da do modelo\n","    output = modelo.generate(tokens, max_length=max_length, num_beams=num_beams, no_repeat_ngram_size=no_repeat_ngram_size, top_k=top_k, top_p=top_p)\n","\n","    # Decodificando a sa√≠da\n","    resposta = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","    return resposta"],"metadata":{"id":"YPW1PFEcu7CV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Exemplo de conversa\n","pergunta = \"Qual √© o papel do presidente na Constitui√ß√£o Federal?\"\n","resposta = gerar_resposta(pergunta, max_length=200, num_beams=8, no_repeat_ngram_size=3, top_k=100, top_p=0.95)\n","resposta"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":177},"id":"JYBAMpzqu-5V","executionInfo":{"status":"ok","timestamp":1707095149025,"user_tz":180,"elapsed":462366,"user":{"displayName":"Andr√© Amorim","userId":"04859568826717067647"}},"outputId":"27ba53ba-0965-46a5-b6cd-58c8307854d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:396: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `100` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["'Qual √© o papel do presidente na Constitui√ß√£o Federal?;;; s√£o s√£o s√£o ‚Äî ‚Äî ‚Äî todas todas ca ca............ caso caso caso se se se dos dos vida vida vida pecado vida vida dos dos dos t√£o t√£o t√£o que que que pessoales pois pois pois sentido sentido sentidodosdosdos da da darrr foi foi foi um um um todo todo todo as as as entre entre seu seu seuororor pode o o o exemplo exemplo exemplo para para para ao ao ao n√£o n√£o n√£odosdos isto isto isto √†s √†s √†s at√© at√© at√© caso caso com com com seus seus seus mas mas mas e e e quer quer quer nem nem nem tem tem tem parece parece parece instintos instintos instintos fala fala fala os os os na na na √† √† √† na na quando quando quando uma uma uma quem quem quem-- forma forma fim fim fim meio meio meiosesese,,'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["# Exemplo de conversa\n","pergunta = \"Qual √© o erro da moral?\"\n","resposta = gerar_resposta(pergunta, max_length=200, num_beams=8, no_repeat_ngram_size=3, top_k=100, top_p=0.95)\n","resposta"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":212},"id":"JG05_xpO2p4J","executionInfo":{"status":"ok","timestamp":1707096512098,"user_tz":180,"elapsed":443181,"user":{"displayName":"Andr√© Amorim","userId":"04859568826717067647"}},"outputId":"0627fa8f-15bc-4ffd-9698-50773cea9d88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:396: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `100` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["'Qual √© o erro da moral? efeito efeito efeitotototo seu seu seu... muito muito muito \" \" \"iii contra contra contra da da da pouco pouco pouco linguagem linguagem linguagem at√© at√© caso caso casoina dessa dessa dessa::: necess√°rio necess√°rio necess√°rio quando quando quando ainda ainda ainda raz√£o raz√£o raz√£o moral moral moral esse esse esse humanidade humanidade humanidade\".\". estado estado estado na na na pela um um um tudo tudo tudo isso isso isso a a a estado estado\".\".\".,,, dos dos dos castra√ß√£oismoismoismo ele ele qualquer qualquer qualquer toda toda toda forma forma forma representa representa representa esp√©cie esp√©cie esp√©cie uma uma uma do do do e e e aos aos aos o o orara em em emdedede h√° h√° h√°--- no no no que que que sem sem sem por√©m por√©m por√©m n√£o n√£o n√£o mais mais mais coisas coisas coisas√°√°√° de de de diz diz diz homem homem homem arte arte artemomomo,,'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["# Fun√ß√£o para recuperar documentos relevantes do VectorDB\n","def recuperar_documentos_relevantes(pergunta, num_documentos=5):\n","    documentos_relevantes = memory.search(pergunta, top_n=num_documentos)\n","    return [{'text': doc.get('text', doc.get('page_content', '')), 'origem': doc['metadata']['origem']} for doc in documentos_relevantes]"],"metadata":{"id":"RoQ8WCfvvA7N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fun√ß√£o para gerar respostas com RAG\n","def gerar_resposta_rag(pergunta, num_documentos=5, max_length=100, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95):\n","    # Recuperar documentos relevantes\n","    documentos_relevantes = recuperar_documentos_relevantes(pergunta, num_documentos)\n","\n","    # Concatenar documentos relevantes para formar o contexto\n","    contexto = \" \".join([doc['text'] for doc in documentos_relevantes])\n","\n","    # Adicionar a pergunta ao contexto\n","    entrada_modelo = contexto + \" Pergunta: \" + pergunta\n","\n","    # Tokenizar a entrada\n","    tokens = tokenizer.encode(entrada_modelo, return_tensors=\"pt\")\n","\n","    # Obtendo a sa√≠da do modelo\n","    output = modelo.generate(tokens, max_length=max_length, num_beams=num_beams, no_repeat_ngram_size=no_repeat_ngram_size, top_k=top_k, top_p=top_p)\n","\n","    # Decodificando a sa√≠da\n","    resposta = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","    return resposta"],"metadata":{"id":"YTRdIhdexwhV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Primeiro exemplo\n","pergunta = \"Qual √© o papel do presidente na Constitui√ß√£o Federal?\"\n","resposta_rag = gerar_resposta_rag(pergunta)\n","resposta_rag"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"X--ISp0ixzHc","executionInfo":{"status":"ok","timestamp":1707095613793,"user_tz":180,"elapsed":73075,"user":{"displayName":"Andr√© Amorim","userId":"04859568826717067647"}},"outputId":"75e54bab-c625-49f5-c1bc-dda9d03450eb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'     Pergunta: Qual √© o papel do presidente na Constitui√ß√£o Federal? \" \"..).).;; ideia ideia se setata e e primeiro primeiro um um vida vida dos dos t√£o t√£o tanto tanto in in n√£o n√£o mais mais de de humanidade humanidade vez vez sua suatotodosdos-- forma formaii a a maneira maneira os os na na que que'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["# Segundo exemplo\n","pergunta = \"Qual √© o erro da moral?\"\n","resposta_rag = gerar_resposta_rag(pergunta)\n","resposta_rag"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"Nucx2QuE0b09","executionInfo":{"status":"ok","timestamp":1707096578459,"user_tz":180,"elapsed":66364,"user":{"displayName":"Andr√© Amorim","userId":"04859568826717067647"}},"outputId":"5cbcf4d2-48f6-4f7f-d532-7514d7660df5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'     Pergunta: Qual √© o erro da moral? \" \" decad√™ncia decad√™nciaaa-- forma.. suas suas?? a seus seus humanidade humanidade homens homens at√© at√© caso caso se se coisas coisas ser sertt;; guerra que que crist√£ crist√£ diz diz uma umavv a a isso isso tempo tempo esta os os s√£o s√£o!!; nada nada um um √†s √†suu o o todas todas fazer fazeria,,'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":66}]}]}