{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7gVOCTOiDut9"
      ],
      "authorship_tag": "ABX9TyO+8kQCQCJogRGEepgtGJcI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baldros/Large-Language-Models/blob/main/OpenAI_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instala√ß√µes e Importa√ß√µes:\n",
        "\n",
        "Algumas bibliotecas, por padr√£o, n√£o veem intaladas no ambiente virtual do colab, sendo assim √© bom manter esse trecho e √© necess√°rio rod√°-lo toda vez que se rodar o\n",
        "notebook pela primeira vez, assim como as importa√ß√µes:"
      ],
      "metadata": {
        "id": "E5ymAiHCQl7Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcZelPFeQhIo",
        "outputId": "b839fc87-0fa0-4a01-d2e1-692c60fbf270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "# Instala√ß√µes:\n",
        "!pip install requests\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa√ß√µes:\n",
        "import requests\n",
        "import json"
      ],
      "metadata": {
        "id": "jHT-gY60TI1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configura√ß√£o da API:\n",
        "Antes de utilizar o modelo, precisamos configurar a utiliza√ß√£o da API no nosso c√≥digo. Aqui, apesar de acima, termos instalado a biblioteca, vamos trabalhar com requisi√ß√£o."
      ],
      "metadata": {
        "id": "JBpT-LdMQlBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# senha para aut√™ntica√ß√£o:\n",
        "API_KEY = input(\"API KEY\")"
      ],
      "metadata": {
        "id": "0roD3XyxSZBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Nesse c√≥digo, n√£o vou utilizar as solu√ß√µes da biblioteca openai, mas sim\n",
        "vou utilizar um m√©todo por links e tals. √â como est√° sendo feito no tutorial e\n",
        "no momento eu to cansado demais pra ler documenta√ß√£o.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ByTqbSPSToIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defini√ß√£o do dicion√°rio de configura√ß√µes:\n",
        "headers = {'Authorization': f'Bearer {API_KEY}','Content-Type':'application/json'}\n",
        "\n",
        "# Definindo o recebimento de dados:\n",
        "link = 'https://api.openai.com/v1/models'\n",
        "requisicao = requests.get(link,headers=headers) #get para pegar informa√ß√£o, post para enviar uma informa√ß√£o\n",
        "\n",
        "print(requisicao)\n",
        "#print(requisicao.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgaodMRIT1Oi",
        "outputId": "f03bfaee-4bba-4830-8396-148fcbd4520e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checando os modelos dispon√≠veis:\n",
        "\n",
        "Como eu n√£o sei exatamente quais modelos h√°, eu fiz esse trecho aqui pra checar.\n",
        "Eu sei que tem o gpt, que gera textos, mas n√£o sei se tem o Dall-E, que gera imagens, e mais que isso, n√£o sei quais s√£o os modelos que eles disponibilizam, ent√£o, vamos checar."
      ],
      "metadata": {
        "id": "1JwCJTc5CXv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checando os valores:\n",
        "dic = requisicao.json()\n",
        "\n",
        "lista_modelos = []\n",
        "for var in dic['data']:\n",
        "  lista_modelos.append(var['id'])"
      ],
      "metadata": {
        "id": "kCujWUpvWoxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'S√£o {len(lista_modelos)} disponiveis at√© o momento\\n')\n",
        "print('modelos:\\n')\n",
        "display(lista_modelos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x7W-rJ-TZlMp",
        "outputId": "7a561b2b-911d-48c3-8791-3aa859785327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S√£o 64 disponiveis at√© o momento\n",
            "\n",
            "modelos:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['babbage',\n",
              " 'davinci',\n",
              " 'text-davinci-edit-001',\n",
              " 'babbage-code-search-code',\n",
              " 'text-similarity-babbage-001',\n",
              " 'code-davinci-edit-001',\n",
              " 'text-davinci-001',\n",
              " 'ada',\n",
              " 'babbage-code-search-text',\n",
              " 'babbage-similarity',\n",
              " 'code-search-babbage-text-001',\n",
              " 'text-curie-001',\n",
              " 'code-search-babbage-code-001',\n",
              " 'text-ada-001',\n",
              " 'text-embedding-ada-002',\n",
              " 'text-similarity-ada-001',\n",
              " 'curie-instruct-beta',\n",
              " 'gpt-3.5-turbo',\n",
              " 'ada-code-search-code',\n",
              " 'ada-similarity',\n",
              " 'code-search-ada-text-001',\n",
              " 'text-search-ada-query-001',\n",
              " 'gpt-3.5-turbo-0301',\n",
              " 'davinci-search-document',\n",
              " 'ada-code-search-text',\n",
              " 'text-search-ada-doc-001',\n",
              " 'davinci-instruct-beta',\n",
              " 'text-similarity-curie-001',\n",
              " 'code-search-ada-code-001',\n",
              " 'ada-search-query',\n",
              " 'text-search-davinci-query-001',\n",
              " 'curie-search-query',\n",
              " 'davinci-search-query',\n",
              " 'babbage-search-document',\n",
              " 'ada-search-document',\n",
              " 'text-search-curie-query-001',\n",
              " 'whisper-1',\n",
              " 'text-search-babbage-doc-001',\n",
              " 'curie-search-document',\n",
              " 'text-search-curie-doc-001',\n",
              " 'babbage-search-query',\n",
              " 'text-babbage-001',\n",
              " 'text-search-davinci-doc-001',\n",
              " 'text-search-babbage-query-001',\n",
              " 'curie-similarity',\n",
              " 'curie',\n",
              " 'text-davinci-003',\n",
              " 'text-similarity-davinci-001',\n",
              " 'text-davinci-002',\n",
              " 'davinci-similarity',\n",
              " 'cushman:2020-05-03',\n",
              " 'ada:2020-05-03',\n",
              " 'babbage:2020-05-03',\n",
              " 'curie:2020-05-03',\n",
              " 'davinci:2020-05-03',\n",
              " 'if-davinci-v2',\n",
              " 'if-curie-v2',\n",
              " 'if-davinci:3.0.0',\n",
              " 'davinci-if:3.0.0',\n",
              " 'davinci-instruct-beta:2.0.0',\n",
              " 'text-ada:001',\n",
              " 'text-davinci:001',\n",
              " 'text-curie:001',\n",
              " 'text-babbage:001']"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checando se DALL-E est√° disponivel:\n",
        "'DALL¬∑E 2' in lista_modelos"
      ],
      "metadata": {
        "id": "K_4t214PYPbQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0e0e853-0737-45a1-c86e-b6fb5fc5bfa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "  N√£o consegui identificar modelos relacionados a produ√ß√£o de imagem,\n",
        "infelizmente. Ainda n√£o tive tempo de analisar todos os modelos,\n",
        "ent√£o, at√© o momento o que temos s√£o coisas ligadas a produ√ß√£o de texto mesmo.\n",
        "üòï\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "QSiBQ7bEBsdp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Montando o modelo conversacional:\n",
        "Para o primeiro caso, vamos trabalhar com o modelo 'gpt-3.5-turbo', porque √© o que me parece mais atual e √© o que eu conhe√ßo que sirva para os nossos propositos. Mais pra frente, com certeza podemos utilizar outros modelos que nos sejam uteis tamb√©m."
      ],
      "metadata": {
        "id": "7gVOCTOiDut9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo Modelo:\n",
        "id_model = 'gpt-3.5-turbo'\n",
        "\n",
        "# Escrenvendo a mensagem:\n",
        "mensagem = input('Digite sua mensagem:\\n')\n",
        "# mensagem = \" \"\n",
        "\n",
        "# Request Body\n",
        "body_mensagem = {\n",
        "    'model':id_model,\n",
        "    'messages':[{\"role\":'user','content':mensagem}]\n",
        "}\n",
        "\n",
        "body_mensagem = json.dumps(body_mensagem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpVorKLLFzUP",
        "outputId": "6b74a2b8-1b66-49e1-f489-96cf65d5dcaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Digite sua mensagem:\n",
            "Fa√ßa uma resumo do livro \"Punho de Deus\" de Frederick Forsyth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Nota:\n",
        "  O m√©todo POST envia dados no corpo da solicita√ß√£o HTTP, enquanto o m√©todo GET\n",
        "envia dados na URL. Como resultado, as solicita√ß√µes POST s√£o usadas quando √©\n",
        "necess√°rio enviar grandes quantidades de dados, como formul√°rios de inscri√ß√£o,\n",
        "mensagens de email ou arquivos de upload, e as solicita√ß√µes GET s√£o usadas para\n",
        "solicitar recursos de um servidor.\n",
        "\n",
        "  Al√©m disso, os dados enviados por uma solicita√ß√£o POST n√£o s√£o vis√≠veis na\n",
        "URL, enquanto os dados enviados por uma solicita√ß√£o GET s√£o vis√≠veis na URL.\n",
        "Como resultado, as solicita√ß√µes POST s√£o mais seguras e mais adequadas para\n",
        "enviar informa√ß√µes confidenciais, como senhas ou informa√ß√µes de pagamento.\n",
        "\n",
        "  Em resumo, enquanto as solicita√ß√µes GET s√£o usadas para recuperar dados, as\n",
        "solicita√ß√µes POST s√£o usadas para enviar dados.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "r4gBCTBWGEyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo o envio de dados:\n",
        "link = 'https://api.openai.com/v1/chat/completions'\n",
        "requisicao = requests.post(link,headers=headers, data=body_mensagem)\n",
        "print(requisicao)\n",
        "display(requisicao.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "ZF-4cJCRD36d",
        "outputId": "e930db36-8d30-4560-f5b9-d2877b3f8e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'{\"id\":\"chatcmpl-7BjZVo1z7rgA1tuv8Bht7xWGimrcf\",\"object\":\"chat.completion\",\"created\":1683031141,\"model\":\"gpt-3.5-turbo-0301\",\"usage\":{\"prompt_tokens\":26,\"completion_tokens\":356,\"total_tokens\":382},\"choices\":[{\"message\":{\"role\":\"assistant\",\"content\":\"\\\\\"Punho de Deus\\\\\" √© um thriller pol√≠tico que se passa na Inglaterra durante a Guerra Fria. A hist√≥ria come√ßa quando um jovem ingl√™s, Steve Devereaux, √© recrutado pelo servi√ßo secreto brit√¢nico para uma miss√£o na Uni√£o Sovi√©tica. Sua tarefa √© se infiltrar no pa√≠s comunista e localizar um cientista que pode ter desenvolvido uma arma secreta chamada \\\\\"Punho de Deus\\\\\", capaz de causar devasta√ß√£o total.\\\\n\\\\nEnquanto Devereaux se prepara para a miss√£o, um grupo de pol√≠ticos brit√¢nicos planeja um acordo com os sovi√©ticos que pode mudar o rumo da guerra. Mas o servi√ßo secreto acredita que o acordo √© uma armadilha e que os sovi√©ticos n√£o t√™m inten√ß√£o de cumprir suas promessas.\\\\n\\\\nAo chegar na Uni√£o Sovi√©tica, Devereaux enfrenta in√∫meros obst√°culos e desafios, incluindo a desconfian√ßa de seus pr√≥prios colegas. No entanto, ele consegue encontrar o cientista e descobrir que a verdadeira arma secreta √© muito diferente do que foi relatado pelos servi√ßos de intelig√™ncia brit√¢nicos.\\\\n\\\\nNo final, Devereaux e sua equipe conseguem impedir que o acordo pol√≠tico seja assinado e desmantelar a base onde a arma secreta estava localizada. \\\\\"Punho de Deus\\\\\" √© uma hist√≥ria emocionante e cheia de reviravoltas, explorando a tens√£o entre os pa√≠ses durante a Guerra Fria e os riscos envolvidos na espionagem.\"},\"finish_reason\":\"stop\",\"index\":0}]}\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = requisicao.json()\n",
        "mensagem = resposta['choices'][0]['message']['content']"
      ],
      "metadata": {
        "id": "9MUXdrnqGvRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(mensagem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "MXpT5zetQeGf",
        "outputId": "518fc8a4-b296-445b-be0c-57760843a44e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'\"Punho de Deus\" √© um thriller pol√≠tico que se passa na Inglaterra durante a Guerra Fria. A hist√≥ria come√ßa quando um jovem ingl√™s, Steve Devereaux, √© recrutado pelo servi√ßo secreto brit√¢nico para uma miss√£o na Uni√£o Sovi√©tica. Sua tarefa √© se infiltrar no pa√≠s comunista e localizar um cientista que pode ter desenvolvido uma arma secreta chamada \"Punho de Deus\", capaz de causar devasta√ß√£o total.\\n\\nEnquanto Devereaux se prepara para a miss√£o, um grupo de pol√≠ticos brit√¢nicos planeja um acordo com os sovi√©ticos que pode mudar o rumo da guerra. Mas o servi√ßo secreto acredita que o acordo √© uma armadilha e que os sovi√©ticos n√£o t√™m inten√ß√£o de cumprir suas promessas.\\n\\nAo chegar na Uni√£o Sovi√©tica, Devereaux enfrenta in√∫meros obst√°culos e desafios, incluindo a desconfian√ßa de seus pr√≥prios colegas. No entanto, ele consegue encontrar o cientista e descobrir que a verdadeira arma secreta √© muito diferente do que foi relatado pelos servi√ßos de intelig√™ncia brit√¢nicos.\\n\\nNo final, Devereaux e sua equipe conseguem impedir que o acordo pol√≠tico seja assinado e desmantelar a base onde a arma secreta estava localizada. \"Punho de Deus\" √© uma hist√≥ria emocionante e cheia de reviravoltas, explorando a tens√£o entre os pa√≠ses durante a Guerra Fria e os riscos envolvidos na espionagem.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oSaIJIV9RbH3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
